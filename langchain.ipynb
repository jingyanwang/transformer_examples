{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "090b68ad",
   "metadata": {},
   "source": [
    "!pip install langchain==0.0.165"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eacada",
   "metadata": {},
   "source": [
    "# base LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e111de6",
   "metadata": {},
   "source": [
    "https://python.langchain.com/en/latest/modules/models/llms/examples/custom_llm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fe6a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimwa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bcb9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6992b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08fe2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLLM(LLM):\n",
    "    \n",
    "      \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def prompt_to_resoonse(\n",
    "        self,\n",
    "        prompt,\n",
    "        max_length = 128,\n",
    "        ):\n",
    "        inputs = tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\",\n",
    "            )\n",
    "        model_output = model.generate(\n",
    "            **inputs,\n",
    "            output_scores=True,\n",
    "            max_length = max_length,\n",
    "            )\n",
    "        response = tokenizer.batch_decode(\n",
    "            model_output, \n",
    "            skip_special_tokens=True)[0]\n",
    "        return response\n",
    "    \n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "    ) -> str:\n",
    "        \n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "\n",
    "        response = self.prompt_to_resoonse(prompt)\n",
    "        return response\n",
    "    \n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846a3afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jim'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = CustomLLM()\n",
    "llm(\"My name is Jim. Question: What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3ecc8",
   "metadata": {},
   "source": [
    "# prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1bb2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc49a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a good name for a company that makes colorful socks?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(product=\"colorful socks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43d442b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8187c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samsung'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"colorful socks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba01c77",
   "metadata": {},
   "source": [
    "# momory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc7f86ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hi, I'm sorry to hear that. I'm sorry to hear that.\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "output = conversation.predict(input=\"Hi there!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "561a8ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7acb1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "077f5262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydantic.main.ModelMetaclass"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ChatOpenAI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
